{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.linalg as npln\n",
    "import sympy as sp\n",
    "import matplotlib.pyplot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class dist :\n",
    "    def __init__(self, mean, variance) :\n",
    "        self.mean = mean\n",
    "        self.variance = variance\n",
    "    \n",
    "    def __repr__(self) : \n",
    "        return str(\"<mean : \" + str(self.mean) + \", var : \" + str(self.variance) + \">\")\n",
    "        \n",
    "    # http://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians\n",
    "    @staticmethod\n",
    "    def kl(p, q, sym_p = None, sym_q = None) :\n",
    "        if (sym_p == None) : \n",
    "            (m1, v1), (m2, v2) = (p.mean, p.variance), (q.mean, q.variance)\n",
    "            m1, v1, m2, v2 = float(m1), float(v1), float(m2), float(v2)\n",
    "            s1, s2 = np.sqrt(v1), np.sqrt(v2)\n",
    "            return np.log(s2/s1) + (v1 + (m1 - m2)**2)/(2*v2) - 0.5\n",
    "        else :\n",
    "            m1, s1, m2, s2 = sym_p[0], sym_p[1], sym_q[0], sym_q[1]\n",
    "            return (sp.ln(s2/s1) + (s1**2 + (m1 - m2)**2)/(2*s2**2) - 0.5)\n",
    "    \n",
    "    # https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables\n",
    "    @staticmethod\n",
    "    def sum(p, q) : \n",
    "        return dist(p.mean + q.mean, p.variance + q.variance)\n",
    "    \n",
    "    def flip_mean(self) : \n",
    "        return dist(-self.mean, self.variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class edge :\n",
    "    def __init__(self, node_a, node_b, dist = dist(1,1), samples = []) :\n",
    "        self.dist = dist\n",
    "        self.samples = []\n",
    "        self.node_a = node_a\n",
    "        self.node_b = node_b\n",
    "        # node_b is the greater node\n",
    "        # dist should be the greater index node - lower index node\n",
    "        \n",
    "    def __repr__(self) : \n",
    "        return str(self.node_a) + \"-\" + str(self.node_b)\n",
    "    \n",
    "    def has_samples(self) : \n",
    "        # for now we need at least two samples to begin with, because the variance would be zero if sample size is 1.\n",
    "        return len(self.samples) >= 2\n",
    "    \n",
    "    def add_sample(self, sample) :\n",
    "        self.samples.append(sample)\n",
    "            \n",
    "    def weighted_sum_of_squared_errors(self, sym_mean = None, sym_var = None) :\n",
    "        if len(self.samples) == 0 :\n",
    "            raise Exception(\"no samples\")\n",
    "        \n",
    "        sum_of_squared_errors = 0\n",
    "        if sym_mean == None :\n",
    "            mean = self.dist.mean\n",
    "        else :\n",
    "            mean = sym_mean\n",
    "        for s in self.samples :\n",
    "            sum_of_squared_errors += (s - mean)**2\n",
    "        \n",
    "        if sym_var == None : \n",
    "            return sum_of_squared_errors / self.dist.variance\n",
    "        else :\n",
    "            return sum_of_squared_errors / sym_var\n",
    "        \n",
    "    def confidence(self) : \n",
    "        if len(self.samples) == 0 : \n",
    "            raise Exception(\"no samples\")\n",
    "        \n",
    "        err = self.weighted_sum_of_squared_errors()\n",
    "        n = len(self.samples)\n",
    "        return n / (np.sqrt(err)+1)\n",
    "    \n",
    "    def maximum_likelihood_estimator(self) :\n",
    "        samples = self.samples\n",
    "        n = len(samples)\n",
    "        total = 0.0\n",
    "        for sample in samples :\n",
    "            total += sample\n",
    "        \n",
    "        mean = total / n\n",
    "        \n",
    "        errtotal = 0.0\n",
    "        for sample in samples : \n",
    "            errtotal += (sample - mean)**2\n",
    "            \n",
    "        variance = errtotal / n\n",
    "        return dist(mean, variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class graph :\n",
    "    def __init__(self, V) :\n",
    "        self.__matrix = np.empty((V,V), dtype=object)\n",
    "        self.V = V\n",
    "        # we will use edges only in the upper right triangle\n",
    "        for i in range(V) :\n",
    "            for j in range(i+1, V) :\n",
    "                self.__matrix[j, i] = (edge(i, j))\n",
    "    \n",
    "    def __repr__(self) :\n",
    "        V = self.V\n",
    "        display_matrix = np.zeros((V, V), dtype=int)\n",
    "        for i in range(V) : \n",
    "            for j in range(i+1, V) : \n",
    "                display_matrix[i, j] = int(self.get_edge(i, j).dist.mean)\n",
    "        \n",
    "        return str(display_matrix)\n",
    "    \n",
    "    def __index(self, x, y) :\n",
    "        if (x == y) :\n",
    "            raise Exception(\"no self edges\")\n",
    "        \n",
    "        if (x > y) : \n",
    "            return (y, x)\n",
    "        \n",
    "        return (x, y)\n",
    "    \n",
    "    def sampled_edges(self) : \n",
    "        V = self.V\n",
    "        display_matrix = np.zeros((V,V), dtype = int)\n",
    "        for i in range(V) : \n",
    "            for j in range(i+1, V) : \n",
    "                display_matrix[i, j] = int(self.get_edge(i,j).has_samples())\n",
    "                \n",
    "        return display_matrix\n",
    "    \n",
    "    def add_sample(self, x, y, sample) :\n",
    "        x, y = self.__index(x, y)\n",
    "        self.__matrix[y][x].add_sample(sample)\n",
    "    \n",
    "    def set_dist(self, x, y, dist) :\n",
    "        self.get_edge(x, y).dist = dist\n",
    "    \n",
    "    def get_edge(self, x, y) :\n",
    "        x, y = self.__index(x, y)\n",
    "        return self.__matrix[y][x]\n",
    "\n",
    "    def get_sampled_paths(self, x, y, term = 5) :\n",
    "        return self.__get_sampled_paths_helper(x, y, {x}, term)\n",
    "    \n",
    "    def __get_sampled_paths_helper(self, curr, dest, visited_vertices, term = 5) :\n",
    "        if curr == dest :\n",
    "            return [[]]\n",
    "        \n",
    "        if len(visited_vertices) == term : \n",
    "            return None\n",
    "        \n",
    "        total_list_of_paths = []\n",
    "        for i in range(self.V) :\n",
    "            if i not in visited_vertices :\n",
    "                cur_edge = self.get_edge(curr, i)\n",
    "                if (cur_edge.has_samples()) :\n",
    "                    new_visited_vertices = visited_vertices.copy()\n",
    "                    new_visited_vertices.add(i)\n",
    "                    list_of_paths = self.__get_sampled_paths_helper(i, dest, new_visited_vertices)\n",
    "                    \n",
    "                    if list_of_paths == None :\n",
    "                        continue\n",
    "                        \n",
    "                    for path in list_of_paths :\n",
    "                        path.append(cur_edge)\n",
    "                    total_list_of_paths += list_of_paths\n",
    "        \n",
    "        return total_list_of_paths\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class model :\n",
    "    @staticmethod\n",
    "    def path_dist_estimation(path) :\n",
    "        # path length is always greater than 1.\n",
    "        estimation = path[0].dist\n",
    "        \n",
    "        if path[0].node_a == path[1].node_a or path[0].node_a == path[1].node_b : \n",
    "            # node_b - node_a - ... \n",
    "            estimation = path[0].dist.flip_mean()\n",
    "        for i in range(1, len(path)) : \n",
    "            curr = path[i]\n",
    "            prev = path[i-1]\n",
    "            if curr.node_a == prev.node_a or curr.node_a == prev.node_b :\n",
    "                estimation = dist.sum(estimation, curr.dist)# head - ... - node_a - node_b - ... - tail\n",
    "            else :\n",
    "                estimation = dist.sum(estimation, curr.dist.flip_mean())\n",
    "            \n",
    "           \n",
    "        head = path[0].node_a\n",
    "        tail = path[-1].node_a\n",
    "        if path[0].node_a == path[1].node_a or path[0].node_a == path[1].node_b :\n",
    "            head = path[0].node_b # node_b is the end\n",
    "            \n",
    "        if path[-1].node_a == path[-2].node_a or path[-1].node_a == path[-2].node_b :\n",
    "            tail = path[-1].node_b # node_b is the end\n",
    "            \n",
    "        if head > tail :\n",
    "            return estimation.flip_mean() # 0th is greater than last. SWAP\n",
    "            \n",
    "        else : \n",
    "            return estimation # last is greater than 0th\n",
    "    \n",
    "    @staticmethod\n",
    "    def path_confidence_estimation(path) : \n",
    "        sum_of_reciprocals = 0\n",
    "        for edge in path :\n",
    "            sum_of_reciprocals += 1 / edge.confidence()\n",
    "        \n",
    "        return np.sqrt(1 / sum_of_reciprocals)\n",
    "    \n",
    "    @staticmethod\n",
    "    def param_cost_formula(graph, x, y, paths = None) :\n",
    "        edge = graph.get_edge(x, y)\n",
    "        if (paths == None) :\n",
    "            paths = graph.get_sampled_paths(x, y)\n",
    "        if len(paths) == 0 :\n",
    "            return -1, None, None\n",
    "        \n",
    "        m1, s1 = sp.symbols('m1 s1')\n",
    "        cost_sum = 0\n",
    "        for path in paths :\n",
    "            if len(path) == 1 : \n",
    "                continue\n",
    "            path_dist = model.path_dist_estimation(path)\n",
    "            path_confidence = model.path_confidence_estimation(path)\n",
    "            m2 = path_dist.mean\n",
    "            s2 = np.sqrt(path_dist.variance)\n",
    "            cost_sum += dist.kl(0,0,(m1,s1),(m2,s2)) * path_confidence\n",
    "            #cost_sum += (sp.ln(s2/s1) + (s1**2 + (m1 - m2)**2)/(2*s2**2) - 0.5) * path_confidence\n",
    "            cost_sum = sp.simplify(cost_sum)\n",
    "        \n",
    "        if (edge.has_samples()) :\n",
    "            mle = edge.maximum_likelihood_estimator()\n",
    "            n = len(edge.samples)\n",
    "            confidence = np.sqrt(n / (np.sqrt(n) + 1))\n",
    "            cost_sum += dist.kl(0,0,(m1,s1), (mle.mean, np.sqrt(mle.variance))) * confidence\n",
    "        \n",
    "        return (cost_sum, m1, s1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def param_cost_optimize(formula, m, s, mi, si) :\n",
    "        formula = sp.simplify(formula)\n",
    "        # http://homes.soic.indiana.edu/classes/spring2012/csci/b553-hauserk/newtons_method.pdf\n",
    "        fdm = sp.diff(formula, m)\n",
    "        fds = sp.diff(formula, s)\n",
    "        fdmm = sp.diff(fdm, m)\n",
    "        fdms = sp.diff(fdm, s)\n",
    "        fdsm = sp.diff(fds, m)\n",
    "        fdss = sp.diff(fds, s)\n",
    "        \n",
    "        gradient_formula = [fdm, fds]\n",
    "        hessian_formula = [[fdmm, fdms], [fdsm, fdss]]\n",
    "        \n",
    "        x = np.array([mi, si])\n",
    "        counter = 0\n",
    "        while True :\n",
    "            gradient, hessian = model.apply_values(gradient_formula, hessian_formula, {m1: x[0], s1: x[1]})\n",
    "            newx = x - npln.inv(hessian).dot(gradient)\n",
    "            if np.abs(newx[0] - x[0]) < 0.00001 and np.abs(newx[1] - x[1]) < 0.00001:\n",
    "                return x[0], x[1]\n",
    "            \n",
    "            if counter >= 500 :\n",
    "                raise Exception('Infinite loop detected')\n",
    "            x = newx\n",
    "            counter += 1\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_values(gradient_formula, hessian_formula, sub) : \n",
    "        fdm = float(gradient_formula[0].evalf(subs=sub))\n",
    "        fds = float(gradient_formula[1].evalf(subs=sub))\n",
    "        fdmm = float(hessian_formula[0][0].evalf(subs=sub))\n",
    "        fdms = float(hessian_formula[0][1].evalf(subs=sub))\n",
    "        fdsm = float(hessian_formula[1][0].evalf(subs=sub))\n",
    "        fdss = float(hessian_formula[1][1].evalf(subs=sub))\n",
    "        \n",
    "        return np.array([fdm, fds]), np.array([[fdmm, fdms],[fdsm, fdss]])\n",
    "    \n",
    "    @staticmethod\n",
    "    def optimize_edge(graph, x, y, verbose = False) :\n",
    "        formula, m1, s1 = model.param_cost_formula(graph, x, y)\n",
    "        if (formula == -1) : \n",
    "            if (verbose) : \n",
    "                print(\"no path available between \"+ str(x) + \"-\" + str(y))\n",
    "            return\n",
    "        edge = graph.get_edge(x, y)\n",
    "        mi, si = edge.dist.mean, np.sqrt(edge.dist.variance)\n",
    "        mean, stddev = model.param_cost_optimize(formula, m1, s1, mi, si)\n",
    "        edge.dist = dist(mean, stddev**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class simulator : \n",
    "    def __init__(self, V, (min_val, max_val, min_var, max_var), seed = None) :\n",
    "        if seed != None : \n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        self.graph = graph(V)\n",
    "        self.var_table = {}\n",
    "        self.val_table = {}\n",
    "        self.V = V\n",
    "        self.diff_table = np.zeros((V,V), dtype = int)\n",
    "        \n",
    "        for i in range(V) : \n",
    "            self.val_table[i] = min_val + np.random.rand() * (max_val - min_val)\n",
    "            for j in range(i+1, V) : \n",
    "                self.var_table[(i, j)] = min_var + np.random.rand() * (max_var - min_var)\n",
    "                \n",
    "        for i in range(V) : \n",
    "            for j in range(i+1, V) : \n",
    "                self.diff_table[i,j] = self.val_table[i] - self.val_table[j]\n",
    "    \n",
    "    def draw_sample(self, i, j) : \n",
    "        if (i == j) : \n",
    "            raise Exception(\"i cannot be j\")\n",
    "        if (j < i) :\n",
    "            (i, j) = (j, i)\n",
    "            \n",
    "        diff = self.val_table[i] - self.val_table[j]\n",
    "        var = self.var_table[(i, j)]\n",
    "        sample = np.random.normal(diff, np.sqrt(var))\n",
    "        return sample\n",
    "    \n",
    "    def set_samples(self, num = None, x = None, y = None) :\n",
    "        # initialize the edges with two samples each.\n",
    "        if (x != None and y != None) : \n",
    "            edge = self.graph.get_edge(x,y)\n",
    "            edge.add_sample(self.draw_sample(x, y))\n",
    "            edge.add_sample(self.draw_sample(x, y))\n",
    "            return\n",
    "        \n",
    "        if (num != None) : \n",
    "            for i in range(num/2) : \n",
    "                x, y = int(np.random.rand() * self.V), int(np.random.rand() * self.V)\n",
    "                if (x == y) : \n",
    "                    i -= 1\n",
    "                    continue\n",
    "                edge = self.graph.get_edge(x,y)\n",
    "                edge.add_sample(self.draw_sample(x, y))\n",
    "                edge.add_sample(self.draw_sample(x, y))\n",
    "            \n",
    "    def optimize(self, loops) :\n",
    "        V = self.V\n",
    "        for l in range(loops) : \n",
    "            for i in range(V) : \n",
    "                for j in range(i+1, V) : \n",
    "                    model.optimize_edge(self.graph, i, j)\n",
    "                    \n",
    "    def evaluate(self) : \n",
    "        sampled_edges = self.graph.sampled_edges()\n",
    "        graph = self.graph\n",
    "        V = self.V\n",
    "        count = 0.0\n",
    "        total_std = 0\n",
    "        for i in range(V) : \n",
    "            for j in range(i+1, V) : \n",
    "                if (len(graph.get_sampled_paths(i, j)) != 0) : \n",
    "                    count += 1\n",
    "                    true_diff = self.val_table[i] - self.val_table[j]\n",
    "                    true_var = self.var_table[(i,j)]\n",
    "                    dist = self.graph.get_edge(i,j).dist\n",
    "                    mean_diff = np.abs(true_diff - dist.mean)\n",
    "                    std = mean_diff / np.sqrt(true_var)\n",
    "                    total_std += std\n",
    "        \n",
    "        avg_std = total_std / count\n",
    "        return avg_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled edges\n",
      "[[0 1 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n",
      "----------------------------------------------------\n",
      "step 0\n",
      "[[0 1 1 1 1]\n",
      " [0 0 1 1 1]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]]\n",
      "avg_err : 124.746607017\n",
      "----------------------------------------------------\n",
      "step 1\n",
      "[[    0 -1424   -32 -3141     1]\n",
      " [    0     0  2982 -1132     1]\n",
      " [    0     0     0 -3236     1]\n",
      " [    0     0     0     0     1]\n",
      " [    0     0     0     0     0]]\n",
      "avg_err : 37.9047926103\n",
      "----------------------------------------------------\n",
      "step 2\n",
      "[[    0 -2997    84 -3165     1]\n",
      " [    0     0  3120  -141     1]\n",
      " [    0     0     0 -3235     1]\n",
      " [    0     0     0     0     1]\n",
      " [    0     0     0     0     0]]\n",
      "avg_err : 1.74183688661\n",
      "----------------------------------------------------\n",
      "step 3\n",
      "[[    0 -3027    72 -3160     1]\n",
      " [    0     0  3130  -117     1]\n",
      " [    0     0     0 -3235     1]\n",
      " [    0     0     0     0     1]\n",
      " [    0     0     0     0     0]]\n",
      "avg_err : 0.775957835472\n",
      "----------------------------------------------------\n",
      "step 4\n",
      "[[    0 -3028    79 -3159     1]\n",
      " [    0     0  3130  -116     1]\n",
      " [    0     0     0 -3235     1]\n",
      " [    0     0     0     0     1]\n",
      " [    0     0     0     0     0]]\n",
      "avg_err : 0.832574078635\n",
      "----------------------------------------------------\n",
      "step 5\n",
      "[[    0 -3028    79 -3159     1]\n",
      " [    0     0  3130  -116     1]\n",
      " [    0     0     0 -3235     1]\n",
      " [    0     0     0     0     1]\n",
      " [    0     0     0     0     0]]\n",
      "avg_err : 0.841892039823\n",
      "----------------------------------------------------\n",
      "true values\n",
      "[[    0 -3058    67 -3160   607]\n",
      " [    0     0  3126  -101  3665]\n",
      " [    0     0     0 -3228   539]\n",
      " [    0     0     0     0  3767]\n",
      " [    0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "s = simulator(5, (0, 4000, 50, 500), 12)\n",
    "s.set_samples(0, 0, 1)\n",
    "s.set_samples(0, 1, 2)\n",
    "s.set_samples(0, 0, 3)\n",
    "s.set_samples(0, 3, 2)\n",
    "print(\"sampled edges\")\n",
    "print(s.graph.sampled_edges())\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 0\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 1\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 2\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 3\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 4\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 5\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"true values\")\n",
    "print(s.diff_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled edges\n",
      "[[0 0 1 0 0 1 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "----------------------------------------------------\n",
      "step 0\n",
      "[[0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 0 0 0 0 1 1 1 1]\n",
      " [0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n",
      "avg_err : 74.3612923175\n",
      "----------------------------------------------------\n",
      "step 1\n",
      "[[    0     1     0     1     0  -725  -109     1 -1248  -516]\n",
      " [    0     0     1     1     1     1     1     1     1     1]\n",
      " [    0     0     0     1   -41   -53   -85     1 -1183  -600]\n",
      " [    0     0     0     0     1     1     1     1     1     1]\n",
      " [    0     0     0     0     0   114   110     1   -41   377]\n",
      " [    0     0     0     0     0     0    19     1  -325   -40]\n",
      " [    0     0     0     0     0     0     0     1  -274   476]\n",
      " [    0     0     0     0     0     0     0     0     1     1]\n",
      " [    0     0     0     0     0     0     0     0     0  1122]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n",
      "avg_err : 50.6548368603\n",
      "----------------------------------------------------\n",
      "step 2\n",
      "[[    0     1   -61     1 -1226  -981  -808     1 -1858  -681]\n",
      " [    0     0     1     1     1     1     1     1     1     1]\n",
      " [    0     0     0     1 -1342  -793 -1046     1 -1866  -581]\n",
      " [    0     0     0     0     1     1     1     1     1     1]\n",
      " [    0     0     0     0     0   740   679     1   -41  1102]\n",
      " [    0     0     0     0     0     0  -200     1  -867   285]\n",
      " [    0     0     0     0     0     0     0     1  -759   476]\n",
      " [    0     0     0     0     0     0     0     0     1     1]\n",
      " [    0     0     0     0     0     0     0     0     0  1302]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n",
      "avg_err : 12.1653301589\n",
      "----------------------------------------------------\n",
      "step 3\n",
      "[[    0     1   -35     1 -1845  -982 -1084     1 -1941  -652]\n",
      " [    0     0     1     1     1     1     1     1     1     1]\n",
      " [    0     0     0     1 -1821  -897 -1071     1 -1900  -566]\n",
      " [    0     0     0     0     1     1     1     1     1     1]\n",
      " [    0     0     0     0     0   936   772     1   -41  1260]\n",
      " [    0     0     0     0     0     0  -128     1  -948   357]\n",
      " [    0     0     0     0     0     0     0     1  -838   476]\n",
      " [    0     0     0     0     0     0     0     0     1     1]\n",
      " [    0     0     0     0     0     0     0     0     0  1336]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n",
      "avg_err : 1.86507217684\n",
      "----------------------------------------------------\n",
      "step 4\n",
      "[[    0     1   -41     1 -1902  -985 -1098     1 -1948  -620]\n",
      " [    0     0     1     1     1     1     1     1     1     1]\n",
      " [    0     0     0     1 -1862  -935 -1050     1 -1904  -558]\n",
      " [    0     0     0     0     1     1     1     1     1     1]\n",
      " [    0     0     0     0     0   928   811     1   -41  1293]\n",
      " [    0     0     0     0     0     0  -104     1  -958   378]\n",
      " [    0     0     0     0     0     0     0     1  -858   476]\n",
      " [    0     0     0     0     0     0     0     0     1     1]\n",
      " [    0     0     0     0     0     0     0     0     0  1345]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n",
      "avg_err : 0.962629601868\n",
      "----------------------------------------------------\n",
      "step 5\n",
      "[[    0     1   -42     1 -1906  -986 -1085     1 -1947  -606]\n",
      " [    0     0     1     1     1     1     1     1     1     1]\n",
      " [    0     0     0     1 -1863  -940 -1039     1 -1904  -555]\n",
      " [    0     0     0     0     1     1     1     1     1     1]\n",
      " [    0     0     0     0     0   923   824     1   -41  1303]\n",
      " [    0     0     0     0     0     0   -96     1  -961   384]\n",
      " [    0     0     0     0     0     0     0     1  -863   476]\n",
      " [    0     0     0     0     0     0     0     0     1     1]\n",
      " [    0     0     0     0     0     0     0     0     0  1347]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n",
      "avg_err : 0.963602026349\n",
      "----------------------------------------------------\n",
      "true values\n",
      "[[    0  -518   -26 -2648 -1881  -985 -1079   475 -1928  -584]\n",
      " [    0     0   492 -2129 -1363  -467  -560   994 -1409   -65]\n",
      " [    0     0     0 -2621 -1855  -959 -1053   502 -1901  -557]\n",
      " [    0     0     0     0   766  1662  1568  3124   719  2063]\n",
      " [    0     0     0     0     0   895   802  2357   -46  1297]\n",
      " [    0     0     0     0     0     0   -93  1461  -942   401]\n",
      " [    0     0     0     0     0     0     0  1555  -848   495]\n",
      " [    0     0     0     0     0     0     0     0 -2404 -1060]\n",
      " [    0     0     0     0     0     0     0     0     0  1344]\n",
      " [    0     0     0     0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "s = simulator(10, (0, 4000, 50, 500), 12)\n",
    "s.set_samples(30)\n",
    "print(\"sampled edges\")\n",
    "print(s.graph.sampled_edges())\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 0\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 1\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 2\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 3\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 4\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "s.optimize(1)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"step 5\")\n",
    "print(s.graph)\n",
    "print(\"avg_err : \" + str(s.evaluate()))\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"true values\")\n",
    "print(s.diff_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
